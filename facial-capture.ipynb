{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca7e9701-573f-469d-b309-8db6ee913e06",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Capture images from a camera, identify faces.\n",
    "\n",
    "This runs on JupyterLabs so displaying the image remotely is a little clunky.  Would perform much better if you run the code natively on the device and then create a stream through HTML to remote viewer.\n",
    "\n",
    "Notes:\n",
    "* Install python3-matplotlib and cv2 via apt-get.  May need to further add pip3 install matplotlib in virtual terminal.\n",
    "* Install face_recognition in vertual_env (pip3 install face_recognition)\n",
    "* Install tools on the pi to work out what the camera is: 'apt-get install v4l-utils fswebcam' then 'v4l2-ctl --list-devices' and 'fswebcam -r 1280x720 --no-banner --device /dev/device0 /images/image1.jpg'.\n",
    "* Check permissions on video group for the user running the notebook.  usermod -a -G video <username>.\n",
    "* Inside of Jupyter you cannot use imshow from cv2 if running remote (e.g. JupyterLab) since cv2.imshow() launches locally to the kernel.  Use mathplotlib instead\n",
    "* To take this further and to match faces to live stream images and then label them then look at https://github.com/ageitgey/face_recognition/blob/master/examples/facerec_from_webcam_faster.py\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d96b742-d290-4cf5-9faa-cdefb825765d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import cv2\n",
    "import sys\n",
    "import numpy\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import display, Image\n",
    "import ipywidgets as widgets\n",
    "import threading\n",
    "\n",
    "# Set the debug flag to push more information out to console\n",
    "debug = True\n",
    "flip_image = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aea3cb0f-099f-4bcc-bae3-a4b2667885ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Stop Button for use with display video data\n",
    "stopButton = widgets.ToggleButton(\n",
    "    value=False,\n",
    "    description='Stop',\n",
    "    disabled=False,\n",
    "    button_style='danger', # 'success', 'info', 'warning', 'danger' or ''\n",
    "    tooltip='Description',\n",
    "    icon='square' # (FontAwesome names without the `fa-` prefix)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "924f3d59-288f-4647-a37e-6d5f310e9220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the method for running video capture and displaying button.  Only process every other frame.\n",
    "\n",
    "def view(stop_button):\n",
    "    if(debug): print(f'DEBUG: Capturing video and setting resolution')\n",
    "\n",
    "    # Set a variable to alternate frame processing\n",
    "    process_this_frame = True\n",
    "\n",
    "    # Start a capture and set the size\n",
    "    capture = cv2.VideoCapture(0, apiPreference=cv2.CAP_V4L2)\n",
    "    capture.set(3,640) # set Width\n",
    "    capture.set(4,480) # set Height\n",
    "    \n",
    "    display_handle=display(None, display_id=True)\n",
    "    \n",
    "    while(True):\n",
    "        # Start capturing\n",
    "        return_val, captured_frame = capture.read()\n",
    "\n",
    "        if (process_this_frame):\n",
    "            # Flip camera to be vertical otherwise set the captured frame as the one to be processed\n",
    "            if (flip_image):\n",
    "                frame = cv2.flip(captured_frame,-1)\n",
    "            else:\n",
    "                frame = captured_frame\n",
    "\n",
    "            # Convert to greyscale image for the image classifier to process\n",
    "            grey_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            face_classifier = cv2.CascadeClassifier(cv2.data.haarcascades + \n",
    "                                                    \"haarcascade_frontalface_default.xml\")\n",
    "            face_locations = face_classifier.detectMultiScale(grey_frame, \n",
    "                                                              scaleFactor=1.1, \n",
    "                                                              minNeighbors=5, \n",
    "                                                              minSize=(40, 40))\n",
    "\n",
    "            # Where we have identified a face then draw a box around it\n",
    "            for (top, right, bottom, left) in face_locations:\n",
    "                cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)\n",
    "\n",
    "            # Convert to RGB from BGR and then display it\n",
    "            rgb_convert_result, rgb_frame = cv2.imencode('.jpeg', cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "            display_handle.update(Image(data=rgb_frame.tobytes()))\n",
    "\n",
    "            # Test the STOP button status\n",
    "            if stopButton.value==True:\n",
    "                if(debug): print(f'Stop button pressed, value {stopButton.value}')\n",
    "                capture.release()\n",
    "                display_handle.update(None)\n",
    "                cv2.destroyAllWindows()\n",
    "                \n",
    "        # Make sure we do not process the next frame\n",
    "        process_this_frame = not process_this_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699c1b43-81b1-4c04-b13c-59801fdc6d32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display(stopButton)\n",
    "thread = threading.Thread(target=view, args=(stopButton,))\n",
    "thread.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca08e43-66f7-4c83-a13d-25f6f3ed69a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
